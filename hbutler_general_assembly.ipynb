{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSI Instructor Challenge\n",
    "\n",
    "* Hank Butler\n",
    "\n",
    "* Data Scientist - Grabit Logistics\n",
    "\n",
    "* 2/10/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1. Modeling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1      2      3       4       5        6        7       8   \\\n",
       "0    842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n",
       "1    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
       "2  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
       "3  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
       "4  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
       "\n",
       "        9   ...     22     23      24      25      26      27      28      29  \\\n",
       "0  0.14710  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.07017  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.12790  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.10520  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.10430  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       30       31  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import breast-cancer data set.\n",
    "df = pd.read_csv('breast-cancer.csv', header = None)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID',\n",
       " 'diagnosis',\n",
       " 'radius_mean',\n",
       " 'radius_sd_error',\n",
       " 'radius_worst',\n",
       " 'texture_mean',\n",
       " 'texture_sd_error',\n",
       " 'texture_worst',\n",
       " 'perimeter_mean',\n",
       " 'perimeter_sd_error',\n",
       " 'perimeter_worst',\n",
       " 'area_mean',\n",
       " 'area_sd_error',\n",
       " 'area_worst',\n",
       " 'smoothness_mean',\n",
       " 'smoothness_sd_error',\n",
       " 'smoothness_worst',\n",
       " 'compactness_mean',\n",
       " 'compactness_sd_error',\n",
       " 'compactness_worst',\n",
       " 'concavity_mean',\n",
       " 'concavity_sd_error',\n",
       " 'concavity_worst',\n",
       " 'concave_points_mean',\n",
       " 'concave_points_sd_error',\n",
       " 'concave_points_worst',\n",
       " 'symmetry_mean',\n",
       " 'symmetry_sd_error',\n",
       " 'symmetry_worst',\n",
       " 'fractal_dimension_mean',\n",
       " 'fractal_dimension_sd_error',\n",
       " 'fractal_dimension_worst']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read .txt file with column names\n",
    "with open('field_names.txt') as f:\n",
    "    col_names = f.read().split('\\n')\n",
    "    \n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>radius_sd_error</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>texture_sd_error</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>perimeter_sd_error</th>\n",
       "      <th>...</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>concave_points_sd_error</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>symmetry_sd_error</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>fractal_dimension_sd_error</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID diagnosis  radius_mean  radius_sd_error  radius_worst  \\\n",
       "0    842302         M        17.99            10.38        122.80   \n",
       "1    842517         M        20.57            17.77        132.90   \n",
       "2  84300903         M        19.69            21.25        130.00   \n",
       "3  84348301         M        11.42            20.38         77.58   \n",
       "4  84358402         M        20.29            14.34        135.10   \n",
       "\n",
       "   texture_mean  texture_sd_error  texture_worst  perimeter_mean  \\\n",
       "0        1001.0           0.11840        0.27760          0.3001   \n",
       "1        1326.0           0.08474        0.07864          0.0869   \n",
       "2        1203.0           0.10960        0.15990          0.1974   \n",
       "3         386.1           0.14250        0.28390          0.2414   \n",
       "4        1297.0           0.10030        0.13280          0.1980   \n",
       "\n",
       "   perimeter_sd_error  ...  concavity_worst  concave_points_mean  \\\n",
       "0             0.14710  ...            25.38                17.33   \n",
       "1             0.07017  ...            24.99                23.41   \n",
       "2             0.12790  ...            23.57                25.53   \n",
       "3             0.10520  ...            14.91                26.50   \n",
       "4             0.10430  ...            22.54                16.67   \n",
       "\n",
       "   concave_points_sd_error  concave_points_worst  symmetry_mean  \\\n",
       "0                   184.60                2019.0         0.1622   \n",
       "1                   158.80                1956.0         0.1238   \n",
       "2                   152.50                1709.0         0.1444   \n",
       "3                    98.87                 567.7         0.2098   \n",
       "4                   152.20                1575.0         0.1374   \n",
       "\n",
       "   symmetry_sd_error  symmetry_worst  fractal_dimension_mean  \\\n",
       "0             0.6656          0.7119                  0.2654   \n",
       "1             0.1866          0.2416                  0.1860   \n",
       "2             0.4245          0.4504                  0.2430   \n",
       "3             0.8663          0.6869                  0.2575   \n",
       "4             0.2050          0.4000                  0.1625   \n",
       "\n",
       "   fractal_dimension_sd_error  fractal_dimension_worst  \n",
       "0                      0.4601                  0.11890  \n",
       "1                      0.2750                  0.08902  \n",
       "2                      0.3613                  0.08758  \n",
       "3                      0.6638                  0.17300  \n",
       "4                      0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine breast-cancer data with column names\n",
    "\n",
    "df.columns = col_names\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   ID                          569 non-null    int64  \n",
      " 1   diagnosis                   569 non-null    object \n",
      " 2   radius_mean                 569 non-null    float64\n",
      " 3   radius_sd_error             569 non-null    float64\n",
      " 4   radius_worst                569 non-null    float64\n",
      " 5   texture_mean                569 non-null    float64\n",
      " 6   texture_sd_error            569 non-null    float64\n",
      " 7   texture_worst               569 non-null    float64\n",
      " 8   perimeter_mean              569 non-null    float64\n",
      " 9   perimeter_sd_error          569 non-null    float64\n",
      " 10  perimeter_worst             569 non-null    float64\n",
      " 11  area_mean                   569 non-null    float64\n",
      " 12  area_sd_error               569 non-null    float64\n",
      " 13  area_worst                  569 non-null    float64\n",
      " 14  smoothness_mean             569 non-null    float64\n",
      " 15  smoothness_sd_error         569 non-null    float64\n",
      " 16  smoothness_worst            569 non-null    float64\n",
      " 17  compactness_mean            569 non-null    float64\n",
      " 18  compactness_sd_error        569 non-null    float64\n",
      " 19  compactness_worst           569 non-null    float64\n",
      " 20  concavity_mean              569 non-null    float64\n",
      " 21  concavity_sd_error          569 non-null    float64\n",
      " 22  concavity_worst             569 non-null    float64\n",
      " 23  concave_points_mean         569 non-null    float64\n",
      " 24  concave_points_sd_error     569 non-null    float64\n",
      " 25  concave_points_worst        569 non-null    float64\n",
      " 26  symmetry_mean               569 non-null    float64\n",
      " 27  symmetry_sd_error           569 non-null    float64\n",
      " 28  symmetry_worst              569 non-null    float64\n",
      " 29  fractal_dimension_mean      569 non-null    float64\n",
      " 30  fractal_dimension_sd_error  569 non-null    float64\n",
      " 31  fractal_dimension_worst     569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Initial Look at DF\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID is an integer.\n",
    "\n",
    "diagnosis is an object.\n",
    "\n",
    "The rest are floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick look at 'diagnosis'\n",
    "\n",
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only two values for diagnosis. B is 'benign', M is 'malignant'.\n",
    "\n",
    "From the task we know that we are trying to predict whether a cell is benign or malignant. Thus, we can use diagnosis as our target variable.\n",
    "\n",
    "This is a classification problem with two classes. \n",
    "\n",
    "Further EDA will be conducted until data pre-processing and then modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>radius_sd_error</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>texture_sd_error</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>perimeter_sd_error</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>...</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>concave_points_sd_error</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>symmetry_sd_error</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>fractal_dimension_sd_error</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID  radius_mean  radius_sd_error  radius_worst  texture_mean  \\\n",
       "count  5.690000e+02   569.000000       569.000000    569.000000    569.000000   \n",
       "mean   3.037183e+07    14.127292        19.289649     91.969033    654.889104   \n",
       "std    1.250206e+08     3.524049         4.301036     24.298981    351.914129   \n",
       "min    8.670000e+03     6.981000         9.710000     43.790000    143.500000   \n",
       "25%    8.692180e+05    11.700000        16.170000     75.170000    420.300000   \n",
       "50%    9.060240e+05    13.370000        18.840000     86.240000    551.100000   \n",
       "75%    8.813129e+06    15.780000        21.800000    104.100000    782.700000   \n",
       "max    9.113205e+08    28.110000        39.280000    188.500000   2501.000000   \n",
       "\n",
       "       texture_sd_error  texture_worst  perimeter_mean  perimeter_sd_error  \\\n",
       "count        569.000000     569.000000      569.000000          569.000000   \n",
       "mean           0.096360       0.104341        0.088799            0.048919   \n",
       "std            0.014064       0.052813        0.079720            0.038803   \n",
       "min            0.052630       0.019380        0.000000            0.000000   \n",
       "25%            0.086370       0.064920        0.029560            0.020310   \n",
       "50%            0.095870       0.092630        0.061540            0.033500   \n",
       "75%            0.105300       0.130400        0.130700            0.074000   \n",
       "max            0.163400       0.345400        0.426800            0.201200   \n",
       "\n",
       "       perimeter_worst  ...  concavity_worst  concave_points_mean  \\\n",
       "count       569.000000  ...       569.000000           569.000000   \n",
       "mean          0.181162  ...        16.269190            25.677223   \n",
       "std           0.027414  ...         4.833242             6.146258   \n",
       "min           0.106000  ...         7.930000            12.020000   \n",
       "25%           0.161900  ...        13.010000            21.080000   \n",
       "50%           0.179200  ...        14.970000            25.410000   \n",
       "75%           0.195700  ...        18.790000            29.720000   \n",
       "max           0.304000  ...        36.040000            49.540000   \n",
       "\n",
       "       concave_points_sd_error  concave_points_worst  symmetry_mean  \\\n",
       "count               569.000000            569.000000     569.000000   \n",
       "mean                107.261213            880.583128       0.132369   \n",
       "std                  33.602542            569.356993       0.022832   \n",
       "min                  50.410000            185.200000       0.071170   \n",
       "25%                  84.110000            515.300000       0.116600   \n",
       "50%                  97.660000            686.500000       0.131300   \n",
       "75%                 125.400000           1084.000000       0.146000   \n",
       "max                 251.200000           4254.000000       0.222600   \n",
       "\n",
       "       symmetry_sd_error  symmetry_worst  fractal_dimension_mean  \\\n",
       "count         569.000000      569.000000              569.000000   \n",
       "mean            0.254265        0.272188                0.114606   \n",
       "std             0.157336        0.208624                0.065732   \n",
       "min             0.027290        0.000000                0.000000   \n",
       "25%             0.147200        0.114500                0.064930   \n",
       "50%             0.211900        0.226700                0.099930   \n",
       "75%             0.339100        0.382900                0.161400   \n",
       "max             1.058000        1.252000                0.291000   \n",
       "\n",
       "       fractal_dimension_sd_error  fractal_dimension_worst  \n",
       "count                  569.000000               569.000000  \n",
       "mean                     0.290076                 0.083946  \n",
       "std                      0.061867                 0.018061  \n",
       "min                      0.156500                 0.055040  \n",
       "25%                      0.250400                 0.071460  \n",
       "50%                      0.282200                 0.080040  \n",
       "75%                      0.317900                 0.092080  \n",
       "max                      0.663800                 0.207500  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                            0\n",
       "diagnosis                     0\n",
       "radius_mean                   0\n",
       "radius_sd_error               0\n",
       "radius_worst                  0\n",
       "texture_mean                  0\n",
       "texture_sd_error              0\n",
       "texture_worst                 0\n",
       "perimeter_mean                0\n",
       "perimeter_sd_error            0\n",
       "perimeter_worst               0\n",
       "area_mean                     0\n",
       "area_sd_error                 0\n",
       "area_worst                    0\n",
       "smoothness_mean               0\n",
       "smoothness_sd_error           0\n",
       "smoothness_worst              0\n",
       "compactness_mean              0\n",
       "compactness_sd_error          0\n",
       "compactness_worst             0\n",
       "concavity_mean                0\n",
       "concavity_sd_error            0\n",
       "concavity_worst               0\n",
       "concave_points_mean           0\n",
       "concave_points_sd_error       0\n",
       "concave_points_worst          0\n",
       "symmetry_mean                 0\n",
       "symmetry_sd_error             0\n",
       "symmetry_worst                0\n",
       "fractal_dimension_mean        0\n",
       "fractal_dimension_sd_error    0\n",
       "fractal_dimension_worst       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for any null values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no null values. Considering all the columns, besides the ID and diagnosis columns, are floats, if there were any null values, median imputation would have been used to replace the null values. Medians are typically preferred to means since means can be affected by outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Mean / Median Smoothness and Compactness for Benign and Malignant Tumors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tumor being 'benign' indicates that the cancer is not harmful, where 'malignant' indicates virulent/infectious. In simpler terms, benign means inactive, malignant means active. The diagnosis column can be transformed to a dummy variable where 1 means malignant and 0 means benign. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis'] = df['diagnosis'].apply(lambda x: 1 if x == 'M' else 0)\n",
    "\n",
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2. Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "part2_csv = 'https://gist.githubusercontent.com/jeff-boykin/9e1a450ef152604e6830ce70f4fc1be8/raw/4d42aebc2c2d3f7528a7769248720918e14f2e03/part-2-data.train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12612628</td>\n",
       "      <td>Engineering Systems Analyst</td>\n",
       "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
       "      <td>Dorking, Surrey, Surrey</td>\n",
       "      <td>Dorking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12612830</td>\n",
       "      <td>Stress Engineer Glasgow</td>\n",
       "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
       "      <td>Glasgow, Scotland, Scotland</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 35000/annum 25-35K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12612844</td>\n",
       "      <td>Modelling and simulation analyst</td>\n",
       "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
       "      <td>Hampshire, South East, South East</td>\n",
       "      <td>Hampshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 40000/annum 20-40K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12613049</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 30000/annum 25K-30K negotiable</td>\n",
       "      <td>27500</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12613647</td>\n",
       "      <td>Pioneer, Miser Engineering Systems Analyst</td>\n",
       "      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                              Title  \\\n",
       "0  12612628                        Engineering Systems Analyst   \n",
       "1  12612830                            Stress Engineer Glasgow   \n",
       "2  12612844                   Modelling and simulation analyst   \n",
       "3  12613049  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4  12613647         Pioneer, Miser Engineering Systems Analyst   \n",
       "\n",
       "                                     FullDescription  \\\n",
       "0  Engineering Systems Analyst Dorking Surrey Sal...   \n",
       "1  Stress Engineer Glasgow Salary **** to **** We...   \n",
       "2  Mathematical Modeller / Simulation Analyst / O...   \n",
       "3  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4  Pioneer, Miser  Engineering Systems Analyst Do...   \n",
       "\n",
       "                         LocationRaw LocationNormalized ContractType  \\\n",
       "0            Dorking, Surrey, Surrey            Dorking          NaN   \n",
       "1        Glasgow, Scotland, Scotland            Glasgow          NaN   \n",
       "2  Hampshire, South East, South East          Hampshire          NaN   \n",
       "3     Surrey, South East, South East             Surrey          NaN   \n",
       "4     Surrey, South East, South East             Surrey          NaN   \n",
       "\n",
       "  ContractTime                       Company          Category  \\\n",
       "0    permanent  Gregory Martin International  Engineering Jobs   \n",
       "1    permanent  Gregory Martin International  Engineering Jobs   \n",
       "2    permanent  Gregory Martin International  Engineering Jobs   \n",
       "3    permanent  Gregory Martin International  Engineering Jobs   \n",
       "4    permanent  Gregory Martin International  Engineering Jobs   \n",
       "\n",
       "                                SalaryRaw  SalaryNormalized        SourceName  \n",
       "0              20000 - 30000/annum 20-30K             25000  cv-library.co.uk  \n",
       "1              25000 - 35000/annum 25-35K             30000  cv-library.co.uk  \n",
       "2              20000 - 40000/annum 20-40K             30000  cv-library.co.uk  \n",
       "3  25000 - 30000/annum 25K-30K negotiable             27500  cv-library.co.uk  \n",
       "4              20000 - 30000/annum 20-30K             25000  cv-library.co.uk  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(part2_csv)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Student Sample 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the full script for Student 1. \n",
    "\n",
    "If there is feedback for a chunk of code it will be in a separate sell with the feedback in a markdown cell below it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import LinearRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# Load data\n",
    "d = pd.read_csv('../data/train.csv')\n",
    "\n",
    "\n",
    "# Setup data for prediction\n",
    "x1 = data.SalaryNormalized\n",
    "x2 = pd.get_dummies(data.ContractType)\n",
    "\n",
    "# Setup model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Evaluate model\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "scores = cross_val_score(model, x2, x1, cv=1, scoring='mean_absolute_error')\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import LinearRegression\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to hold off on importing specific moduels from sklearn until you're about to use them. This will help you keep track of what model you're using and not use up a bunch of memory.\n",
    "\n",
    "Also, cross_validation isn't a class in sklearn. Sklearn has great documentation so make sure you're importing from the correct places. Don't worry about remembering all the different modules. Sklearn is a large library, so it's okay if you forget which module something is located, but be sure you know how to use the documentation. This will help you down the road.\n",
    "https://scikit-learn.org/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a better name for your dataframe than simply 'd'. This doesn't really tell you or whoever looks at your code what the data is reflective of and it could be mistaken as a dictionary in other parts of your code.\n",
    "\n",
    "df is commonly used as a convention. You use 'data' later in your file which is also fine. Just be consistent and try not to use names that could be confusing or vague.\n",
    "\n",
    "Also, it's typically a good idea to call the .head() method after importing data to see if the import went well and to get a look at the data. .info(), .shape, and .describe() are also good to call right after importing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data for prediction\n",
    "x1 = data.SalaryNormalized\n",
    "x2 = pd.get_dummies(data.ContractType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some better names for your variables!\n",
    "\n",
    "You can do data.VariableName but typically you'll see:\n",
    "data['VariableName'] which is more conventional.\n",
    "\n",
    "The typical convention is X for predictor variables and y for the target variable. \n",
    "\n",
    "This is derived from the notation y = f(X) which should help explain the convention. We're trying to predict y based on a function of X!\n",
    "\n",
    "If we're assuming that you're trying to predict salary here's what your variables should look like:\n",
    "\n",
    "y = data['SalaryNormalized']\n",
    "\n",
    "and\n",
    "\n",
    "X = data['ContractType']\n",
    "\n",
    "Additionally, there are 12 features in the dataset but only two included in your data preparation. You can start with only a few predictor variables and iteratively add more each time, but it may be easier to start with all features and then drop features with less predictive power after testing the model. Also, only one predictor variable will probably give you a poor model.\n",
    "\n",
    "You should do some imputation for values of data['ContractType']. From a quick look at the dataset, it has missing values and you should consider how you are going to take care of those missing values before converting it to a dummy variable. It only has two different values (full_time or part_time) so it may even be easier to convert it to a binary variable since .get_dummies() adds extra columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a more specific name for your model that indicates what kind of model you are using. This will help you later on if you're using different types of models and need to keep track of which models you have used.\n",
    "\n",
    "It can be something simple like lin_reg = LinearRegression()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a better place to import the cross_val_score. Just make sure you're importing it from the right place! Also, cross_val_score only needs to be imported once!\n",
    "\n",
    "train_test_split is in sklearn.model_selection. You also didn't specify a train_test_split for your model. Typically you only want to import a class or module if you're going to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, x2, x1, cv=1, scoring='mean_absolute_error')\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, this ties back to why you need to have better names for your variables. It's not clear which one is the target and it could be in the wrong spot in the call of cross_val_score.\n",
    "\n",
    "cv = 1. You might want to use a larger number on this. In most common cross-validation approaches you use part of the training set for testing. You do this several times so that each data point appears once in the test set. By setting this equal to 1, you're essentially using the entire dataset without splitting the dataset and sampling different subsets. This won't help train the model. You should set cv to at least 2, but I have seen 3 or 5 usually used. \n",
    "Here's a link to read up more on cross-validation if you're struggling to grasp it.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\n",
    "\n",
    "Calling scores.mean() will give you the mean score of all iterations. Consider calling scores by itself to see the scores across the different cv folds in addition to calling just the mean.\n",
    "\n",
    "'Mean_absolute_error' is a good metric for seeing how a regression model performs so that should be okay!\n",
    "\n",
    "Here's how you can use train_test_split to set up and fit the data to your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suggested code for fitting and training the model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# creating X and y\n",
    "X = df['predictor_variables']\n",
    "y = df['target']\n",
    "\n",
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)\n",
    "\n",
    "# Initialize the model\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "# See how model performs\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "print(\"Training Score: {:.3f}\".format(lin_reg.score(X_train, y_train)))\n",
    "print(\"Test Score: {:.3f}\".format(lin_reg.score(X_test, y_test)))\n",
    "print(\"Coefficients: {:.3f}\".format(lin_reg.coef_))\n",
    "print(\"MSE: {:.3f}\".format(mean_squared_error(y_test, y_pred)))\n",
    "print(\"R2 Score: {:.3f}\".format(r2_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Student Sample 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('../data/train.csv')\n",
    "\n",
    "\n",
    "# Setup data for prediction\n",
    "y = data.SalaryNormalized\n",
    "X = pd.get_dummies(data.ContractType)\n",
    "\n",
    "# Setup model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Evaluate model\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='mean_absolute_error')\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe .cross_validation isn't a module in sklearn. It should be in sklearn.model_selection. \n",
    "\n",
    "Don't feel bad about this stuff. It's very common to forget all the different modules in sklearn. The documentation for sklearn is very good and helpful!\n",
    "\n",
    "https://scikit-learn.org/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing data, consider calling .head() on your data frame to get a quick look. This will help you ensure the data was imported correctly. \n",
    ".shape, .info(), and .describe() can also provide some good insight into what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.SalaryNormalized\n",
    "X = pd.get_dummies(data.ContractType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data.SalaryNormalized is perfectly valid but it's usually preferred to use\n",
    "data['SalaryNormalize']. It makes it clearer that you're using a variable and not calling an attribute or method on your data frame.\n",
    "\n",
    "There appears to be more features in the data set than you've included in X. You may want to consider adding in all features initially then removing features that have little to no predictive power. By only including one variable your model may not have strong predictive power.\n",
    "\n",
    "You should do some imputation for values of data['ContractType']. From a quick look at the dataset, it has missing values and you should consider how you are going to take care of those missing values before converting it to a dummy variable. It only has two different values (full_time or part_time) so it may even be easier to convert it to a binary variable since .get_dummies() adds extra columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is more of a personal preference, but you may want to be more specific with the name for your model in case you try multiple models or variations of the same model. \n",
    "\n",
    "I typically use an abbreviation of the model I'm using such as:\n",
    "\n",
    "lin_reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, X, y, cv=5, scoring='mean_absolute_error')\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting CV = 5 is a good job. This will make sure the model sees all data points in the training and test sets. Mean Absolute Error is a good metric for evaluating a regression as well.\n",
    "\n",
    "By printing the scores.mean() you should get a good idea how the model is performing. It may be helpful to print(scores) to see how it model performed across different folds.\n",
    "\n",
    "If it's performing poorly you may want to consider adding more features, using a different type of model, and/or doing a train_test_split instead of just CV. \n",
    "\n",
    "You could even do a GridSearchCV, but it will take a long time to run. \n",
    "\n",
    "Good work, hopefully you have a good model!."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
